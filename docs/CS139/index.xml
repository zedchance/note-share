<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CS139 on Notes</title>
    <link>http://zedchance.github.io/notes/CS139/</link>
    <description>Recent content in CS139 on Notes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="http://zedchance.github.io/notes/CS139/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>CS139-lecture-20210831</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20210831/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20210831/</guid>
      <description>Course orientation #  File: 139-syllabus.pdf  Notes during orientation #   We will be looking at operating systems from a conceptual level, not any specific OS Files will be submitted as .tar.gz, NOT .zip  Introduction #  File: csc139-fall21-part0-logistics.pdf  </description>
    </item>
    
    <item>
      <title>CS139-lecture-20210902</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20210902/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20210902/</guid>
      <description>Introduction to Operating systems #  What is an OS? #  The OS is the intermediary between the hardware and the software.
Possibly the most famous test program in C:
#include &amp;lt;stdio.h&amp;gt; int main() { printf(&amp;#34;Hello, world!\n&amp;#34;); exit 0; } Which is compiled via
gcc hello.c -o hello which creates the executable hello.
We can run this via
./hello we can run this with 2 instances like
./hello &amp;amp; .</description>
    </item>
    
    <item>
      <title>CS139-lecture-20210907</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20210907/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20210907/</guid>
      <description>Introduction cont #  Parallel systems #  Intrachip transfer is much faster than interchip transfer.
Distributed systems #  Real-time and embedded systems #  Other systems #  Organization #   PC = program counter, the address of the next instruction IR = instruction register, the address of the current instruction MAR = memory address register, address of the next memory IO MBR = memory buffer register, actual data to be read/written to/from memory I/O AR = input output address I/O BR = input output buffer register, the data  Memory is an array of bytes, each with its own address.</description>
    </item>
    
    <item>
      <title>CS139-lecture-20210909</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20210909/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20210909/</guid>
      <description>Organization cont #  Interrupts cont #  During a IO request:
 Device driver loads the registers in the device controller Device controller examines content Device controller starts the transfer of data Once the transfer is done, the device controller informs the operating system that the transfer is complete. Driver gives control back to the OS  Handling interrupts #  When calling a interrupt routine, we have 2 methods:</description>
    </item>
    
    <item>
      <title>CS139-lecture-20210914</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20210914/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20210914/</guid>
      <description>Structure cont #  Simple structure #  Layered structure #  A 5 layered approach:
5. operator 4. user programs 3. IO management 2. communication 1. memory management 0. CPU, support for multi program This is easier to construct and debug, however there is a communication overhead. It is impractical to divide the kernel into layers.
Microkernel structure #  Microkernels are easier to extend, but there is a lot of communication overhead.</description>
    </item>
    
    <item>
      <title>CS139-lecture-20210916</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20210916/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20210916/</guid>
      <description>Processes cont. #  Scheduling cont. #  A single linked list works well for ready and wait queues. Note the addition of a tail pointer. The tail pointer gives us a constant time complexity to get to the end of the queue. New processes are added at the tail.
Schedulers #  Note the difference between short-term and long-term schedulers. Long-term scheduling handles multiprogramming.
Note: Read more on medium term scheduling in the text.</description>
    </item>
    
    <item>
      <title>CS139-lecture-20210921</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20210921/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20210921/</guid>
      <description>Processes cont. #  Termination #  A parent cannot wait on a grandchild.
Inter-process communication #  Message passing
 uses send and receieve API calls slower, more expensive small amount of data distributed   Shared memory
 process A sets aside some memory for process B restrictions must be lifted by kernel faster and cheaper because minimal kernel involvement doesn&amp;rsquo;t work for distributed systems (2 processes on remote machines)    Shared memory communication #  This uses a circular buffer:</description>
    </item>
    
    <item>
      <title>CS139-lecture-20210923</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20210923/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20210923/</guid>
      <description>Processes cont. #  Using fork and execl #  Consider this code
pid_t pid1, pid2; int status; struct rusage usage; if ((pid1=fork())) { printf(&amp;#34;I am parent %d; child is %d\n&amp;#34;,getpid(),pid1); pid2=wait3(&amp;amp;status, 0, &amp;amp;usage); printf(&amp;#34;exit code for %d is %d\n&amp;#34;, pid2, status); } else { execl(&amp;#34;/bin/cat&amp;#34;, &amp;#34;/bin/cat&amp;#34;, &amp;#34;/csc/139/news/0001.txt&amp;#34;, NULL); printf(&amp;#34;we should never get here!\n&amp;#34;); } execl loads cat into the child&amp;rsquo;s memory space. When this child cat exits, it will never reach the subsequent printf.</description>
    </item>
    
    <item>
      <title>CS139-lecture-20210928</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20210928/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20210928/</guid>
      <description>Threads cont. #  How TCBs are mapped to the processes address space.
User-level threads #  Multithreading models #  The bottleneck created by the many-to-one model can be alleviated in the one-to-one model.
The M:M model maintains slightly more user threads than kernel threads.
So why do the biggest OSes use the one-to-one model? More cores in CPUs, more CPUs in general.
Thread libraries #  Implicit threading #  Issues #  Single threaded  Multi-threaded has 2 possibilities The child can either have 1 thread (the invoking thread), or all.</description>
    </item>
    
    <item>
      <title>CS139-lecture-20210930</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20210930/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20210930/</guid>
      <description>CPU scheduling #  Long term scheduling
 job scheduling decides which process should enter the ready state   Short term scheduling
 cpu scheduling decides which ready process should run next on the CPU    Recall the overall state diagram for a process:
Non-preemptive vs preemptive scheduling #  Preemptive here basically means &amp;ldquo;pause&amp;rdquo;. So the non-preemptive scheduling can only work in cases 1 and 4 (from prior slides).</description>
    </item>
    
    <item>
      <title>CS139-lecture-20211005</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20211005/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20211005/</guid>
      <description>CPU scheduling cont. #  I/O Bursts #  Round robin #  Round robin strives on optimizing average response time.
If we make the value of   \( q \)  too small, we will have a lot of overhead due to context switches.
Priority scheduling #  Technically, shortest job first is a type of priority scheduling (prioritizing shortest burst time).
Multilevel queue #  Scheduling in Linux (CFS) #  Priority levels are 0-139.</description>
    </item>
    
    <item>
      <title>CS139-lecture-20211007</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20211007/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20211007/</guid>
      <description>Scheduling cont. #  CFS cont. #  Recall that vruntime is a function, not the actual runtime of the process. The progress rate depends on the priority of the process.
 faster progress rate for low priority process slower progress for high priority process  Since we are always looking for the leftmost node in the process run queue, we can maintain a pointer to get the min value in constant time.</description>
    </item>
    
    <item>
      <title>CS139-lecture-20211021</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20211021/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20211021/</guid>
      <description>Process synchronization #  Race condition #  Critical selection and mutual exclusion #  In the above code examples, the counter++ and counter-- are considered a critical section.
How to implement mutual exclusion #  Note: This solution isn&amp;rsquo;t fully correct.  producer: while (lock == 0) lock = 1 put lock = 0 consumer: while (lock == 0) lock = 1 fetch lock = 0 The problem with this code is that if the OS does a context switch during a critical section, it can create an error.</description>
    </item>
    
    <item>
      <title>CS139-lecture-20211026</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20211026/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20211026/</guid>
      <description>Synchronization cont. #  Since these could output in any order, we can setup semaphores to ensure the run order.
Bounded buffer problem #   full and empty are counting semaphores.  full notifies consumers how many items are there empty notifies producers how many empty slots available   mutex is a binary semaphore.   mutex starts at 1, &amp;ldquo;unlocked&amp;rdquo;, so the first process can have mutual exclusion full is set to 0, and empty is set to n, because all slots are available   The first wait(empty) checks if there is an empty slot wait(mutex) checks if there is a process accessing the shared buffer wait(full) checks if there is any items to consume  Consider switching the order of the first to wait functions, to:</description>
    </item>
    
    <item>
      <title>CS139-lecture-20211028</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20211028/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20211028/</guid>
      <description>Synchronization cont. #  Weakness of the semaphore #  In class exercises #   2 semaphores, 1 mutex semaphore allowing access to laoding zone, and 1 counting semaphore checking if there is a car waiting mutex initialized to 1 (unlocked) car counting semaphore initialized to   \( n \)     2 binary semaphores, with ping&amp;rsquo;s semaphore being set to 1 initially, and pong&amp;rsquo;s being set to 0.</description>
    </item>
    
    <item>
      <title>CS139-lecture-20211102</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20211102/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20211102/</guid>
      <description>Deadlocks cont. #  Resource allocation graph cont. #     \( P_2 \)  and  \( P_4 \)  have the ability to exit, so the resources they hold will be allocated elsewhere. No deadlock.
We can use a depth first search to look for cycles, to detect the possibility of deadlock.
Methods for handling deadlocks #   to impose total order: if we have multiple resources, force process requests for resources in an increasing order of enumeration  So, from the example before, if we swap the order in which each thread obtains lock (so they request the locks in the same order), we eliminate the deadlock:</description>
    </item>
    
    <item>
      <title>CS139-lecture-20211104</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20211104/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20211104/</guid>
      <description>Deadlocks cont #  Banker&amp;rsquo;s algorithm cont. #  Recall that the safety subroutine simulates allocating all resources, and if able to if returns true (because it is considered a safe state). If it is unable to simulate allocating all resources, it will return false.
The second subroutine of the Banker&amp;rsquo;s algorithm is the resource request:
 simulates allocating resource requests by modifying the state of the process if safe, the resources can be allocated otherwise, it has to wait  Example using Banker&amp;rsquo;s algorithm #  So first we run the safety algorithm:</description>
    </item>
    
    <item>
      <title>CS139-lecture-20211109</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20211109/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20211109/</guid>
      <description>Memory Management #   recall, CPU does not have direct access to the disk, it must use the bus   note that the OS itself is a program residing in memory  Addresses #   notice that logically, the address 99 and 100 are next to each other in the purple program. However, physically they are not adjacent (non contiguous).  There are other types of addresses:</description>
    </item>
    
  </channel>
</rss>
