<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CS139 on Notes</title>
    <link>http://zedchance.github.io/notes/CS139/</link>
    <description>Recent content in CS139 on Notes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="http://zedchance.github.io/notes/CS139/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>CS139-lecture-20210831</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20210831/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20210831/</guid>
      <description>Course orientation #  File: 139-syllabus.pdf  Notes during orientation #   We will be looking at operating systems from a conceptual level, not any specific OS Files will be submitted as .tar.gz, NOT .zip  Introduction #  File: csc139-fall21-part0-logistics.pdf  </description>
    </item>
    
    <item>
      <title>CS139-lecture-20210902</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20210902/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20210902/</guid>
      <description>Introduction to Operating systems #  What is an OS? #  The OS is the intermediary between the hardware and the software.
Possibly the most famous test program in C:
#include &amp;lt;stdio.h&amp;gt; int main() { printf(&amp;#34;Hello, world!\n&amp;#34;); exit 0; } Which is compiled via
gcc hello.c -o hello which creates the executable hello.
We can run this via
./hello we can run this with 2 instances like
./hello &amp;amp; .</description>
    </item>
    
    <item>
      <title>CS139-lecture-20210907</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20210907/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20210907/</guid>
      <description>Introduction cont #  Parallel systems #  Intrachip transfer is much faster than interchip transfer.
Distributed systems #  Real-time and embedded systems #  Other systems #  Organization #   PC = program counter, the address of the next instruction IR = instruction register, the address of the current instruction MAR = memory address register, address of the next memory IO MBR = memory buffer register, actual data to be read/written to/from memory I/O AR = input output address I/O BR = input output buffer register, the data  Memory is an array of bytes, each with its own address.</description>
    </item>
    
    <item>
      <title>CS139-lecture-20210909</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20210909/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20210909/</guid>
      <description>Organization cont #  Interrupts cont #  During a IO request:
 Device driver loads the registers in the device controller Device controller examines content Device controller starts the transfer of data Once the transfer is done, the device controller informs the operating system that the transfer is complete. Driver gives control back to the OS  Handling interrupts #  When calling a interrupt routine, we have 2 methods:</description>
    </item>
    
    <item>
      <title>CS139-lecture-20210914</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20210914/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20210914/</guid>
      <description>Structure cont #  Simple structure #  Layered structure #  A 5 layered approach:
5. operator 4. user programs 3. IO management 2. communication 1. memory management 0. CPU, support for multi program This is easier to construct and debug, however there is a communication overhead. It is impractical to divide the kernel into layers.
Microkernel structure #  Microkernels are easier to extend, but there is a lot of communication overhead.</description>
    </item>
    
    <item>
      <title>CS139-lecture-20210916</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20210916/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20210916/</guid>
      <description>Processes cont. #  Scheduling cont. #  A single linked list works well for ready and wait queues. Note the addition of a tail pointer. The tail pointer gives us a constant time complexity to get to the end of the queue. New processes are added at the tail.
Schedulers #  Note the difference between short-term and long-term schedulers. Long-term scheduling handles multiprogramming.
Note: Read more on medium term scheduling in the text.</description>
    </item>
    
    <item>
      <title>CS139-lecture-20210921</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20210921/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20210921/</guid>
      <description>Processes cont. #  Termination #  A parent cannot wait on a grandchild.
Inter-process communication #  Message passing
 uses send and receieve API calls slower, more expensive small amount of data distributed   Shared memory
 process A sets aside some memory for process B restrictions must be lifted by kernel faster and cheaper because minimal kernel involvement doesn&amp;rsquo;t work for distributed systems (2 processes on remote machines)    Shared memory communication #  This uses a circular buffer:</description>
    </item>
    
    <item>
      <title>CS139-lecture-20210923</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20210923/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20210923/</guid>
      <description>Processes cont. #  Using fork and execl #  Consider this code
pid_t pid1, pid2; int status; struct rusage usage; if ((pid1=fork())) { printf(&amp;#34;I am parent %d; child is %d\n&amp;#34;,getpid(),pid1); pid2=wait3(&amp;amp;status, 0, &amp;amp;usage); printf(&amp;#34;exit code for %d is %d\n&amp;#34;, pid2, status); } else { execl(&amp;#34;/bin/cat&amp;#34;, &amp;#34;/bin/cat&amp;#34;, &amp;#34;/csc/139/news/0001.txt&amp;#34;, NULL); printf(&amp;#34;we should never get here!\n&amp;#34;); } execl loads cat into the child&amp;rsquo;s memory space. When this child cat exits, it will never reach the subsequent printf.</description>
    </item>
    
    <item>
      <title>CS139-lecture-20210928</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20210928/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20210928/</guid>
      <description>Threads cont. #  How TCBs are mapped to the processes address space.
User-level threads #  Multithreading models #  The bottleneck created by the many-to-one model can be alleviated in the one-to-one model.
The M:M model maintains slightly more user threads than kernel threads.
So why do the biggest OSes use the one-to-one model? More cores in CPUs, more CPUs in general.
Thread libraries #  Implicit threading #  Issues #  Single threaded  Multi-threaded has 2 possibilities The child can either have 1 thread (the invoking thread), or all.</description>
    </item>
    
    <item>
      <title>CS139-lecture-20210930</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20210930/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20210930/</guid>
      <description>CPU scheduling #  Long term scheduling
 job scheduling decides which process should enter the ready state   Short term scheduling
 cpu scheduling decides which ready process should run next on the CPU    Recall the overall state diagram for a process:
Non-preemptive vs preemptive scheduling #  Preemptive here basically means &amp;ldquo;pause&amp;rdquo;. So the non-preemptive scheduling can only work in cases 1 and 4 (from prior slides).</description>
    </item>
    
    <item>
      <title>CS139-lecture-20211005</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20211005/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20211005/</guid>
      <description>CPU scheduling cont. #  I/O Bursts #  Round robin #  Round robin strives on optimizing average response time.
If we make the value of   \( q \)  too small, we will have a lot of overhead due to context switches.
Priority scheduling #  Technically, shortest job first is a type of priority scheduling (prioritizing shortest burst time).
Multilevel queue #  Scheduling in Linux (CFS) #  Priority levels are 0-139.</description>
    </item>
    
    <item>
      <title>CS139-lecture-20211007</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20211007/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20211007/</guid>
      <description>Scheduling cont. #  CFS cont. #  Recall that vruntime is a function, not the actual runtime of the process. The progress rate depends on the priority of the process.
 faster progress rate for low priority process slower progress for high priority process  Since we are always looking for the leftmost node in the process run queue, we can maintain a pointer to get the min value in constant time.</description>
    </item>
    
  </channel>
</rss>
