<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>lexers on Notes</title>
    <link>http://zedchance.github.io/notes/tags/lexers/</link>
    <description>Recent content in lexers on Notes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="http://zedchance.github.io/notes/tags/lexers/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>CS135-lecture-20210405</title>
      <link>http://zedchance.github.io/notes/CS135/CS135-lecture-20210405/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS135/CS135-lecture-20210405/</guid>
      <description>Introduction to Compilers #  Structure of a compiler #  The economy of programming languages #  Lexical analysis #  Lexical examples #  Lexical specification #  Introduction to parsing #  Predictive parsing #  </description>
    </item>
    
    <item>
      <title>CS135-lecture-20210407</title>
      <link>http://zedchance.github.io/notes/CS135/CS135-lecture-20210407/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS135/CS135-lecture-20210407/</guid>
      <description>Compiler front end #  Compilers are presented with source code, and that goes through the front end of the compiler. This front end builds a parse tree and sends that to the back end of the compiler. The back end produces an executable.
The front end is composed of multiple steps
 Lexical analysis, sometimes called the scanner. This takes the source code and produces tokens. Syntactic analysis, called a parser.</description>
    </item>
    
    <item>
      <title>CS135-lecture-20210419</title>
      <link>http://zedchance.github.io/notes/CS135/CS135-lecture-20210419/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS135/CS135-lecture-20210419/</guid>
      <description>Lexical specification to DFA #  WORD: aa+aaa OTHER: aa* Heres an NFA for each regular expression:
So now we can take the NFA and make a DFA out of it. Recall, the scanner will need to use a DFA.
Then we can label the accept states with the lexeme types:
So for example, to scan this sequence:
a aa aaa aaaa Nullablity #  A non-terminal, or a sequence of non-terminals, is nullable if the empty string can be derived from it.</description>
    </item>
    
  </channel>
</rss>
