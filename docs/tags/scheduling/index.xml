<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>scheduling on Notes</title>
    <link>http://zedchance.github.io/notes/tags/scheduling/</link>
    <description>Recent content in scheduling on Notes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="http://zedchance.github.io/notes/tags/scheduling/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>CS139-lecture-20210914</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20210914/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20210914/</guid>
      <description>Structure cont #  Simple structure #  Layered structure #  A 5 layered approach:
5. operator 4. user programs 3. IO management 2. communication 1. memory management 0. CPU, support for multi program This is easier to construct and debug, however there is a communication overhead. It is impractical to divide the kernel into layers.
Microkernel structure #  Microkernels are easier to extend, but there is a lot of communication overhead.</description>
    </item>
    
    <item>
      <title>CS139-lecture-20210916</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20210916/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20210916/</guid>
      <description>Processes cont. #  Scheduling cont. #  A single linked list works well for ready and wait queues. Note the addition of a tail pointer. The tail pointer gives us a constant time complexity to get to the end of the queue. New processes are added at the tail.
Schedulers #  Note the difference between short-term and long-term schedulers. Long-term scheduling handles multiprogramming.
Note: Read more on medium term scheduling in the text.</description>
    </item>
    
    <item>
      <title>CS139-lecture-20210930</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20210930/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20210930/</guid>
      <description>CPU scheduling #  Long term scheduling
 job scheduling decides which process should enter the ready state   Short term scheduling
 cpu scheduling decides which ready process should run next on the CPU    Recall the overall state diagram for a process:
Non-preemptive vs preemptive scheduling #  Preemptive here basically means &amp;ldquo;pause&amp;rdquo;. So the non-preemptive scheduling can only work in cases 1 and 4 (from prior slides).</description>
    </item>
    
    <item>
      <title>CS139-lecture-20211005</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20211005/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20211005/</guid>
      <description>CPU scheduling cont. #  I/O Bursts #  Round robin #  Round robin strives on optimizing average response time.
If we make the value of   \( q \)  too small, we will have a lot of overhead due to context switches.
Priority scheduling #  Technically, shortest job first is a type of priority scheduling (prioritizing shortest burst time).
Multilevel queue #  Scheduling in Linux (CFS) #  Priority levels are 0-139.</description>
    </item>
    
    <item>
      <title>CS139-lecture-20211007</title>
      <link>http://zedchance.github.io/notes/CS139/CS139-lecture-20211007/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://zedchance.github.io/notes/CS139/CS139-lecture-20211007/</guid>
      <description>Scheduling cont. #  CFS cont. #  Recall that vruntime is a function, not the actual runtime of the process. The progress rate depends on the priority of the process.
 faster progress rate for low priority process slower progress for high priority process  Since we are always looking for the leftmost node in the process run queue, we can maintain a pointer to get the min value in constant time.</description>
    </item>
    
  </channel>
</rss>
